{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9kxq01msMg9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlxtend\n",
      "  Downloading mlxtend-0.18.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Requirement already satisfied: scipy>=1.2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlxtend) (1.5.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlxtend) (50.3.1.post20201107)\n",
      "Requirement already satisfied: pandas>=0.24.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlxtend) (1.1.3)\n",
      "Requirement already satisfied: matplotlib>=3.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlxtend) (3.3.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlxtend) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlxtend) (1.19.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from mlxtend) (0.17.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from pandas>=0.24.2->mlxtend) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (8.0.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (2020.6.20)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from matplotlib>=3.0.0->mlxtend) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.3->mlxtend) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->mlxtend) (1.15.0)\n",
      "Installing collected packages: mlxtend\n",
      "Successfully installed mlxtend-0.18.0\n",
      "Requirement already satisfied: h5py in c:\\users\\alex\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\alex\\anaconda3\\lib\\site-packages (5.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\alex\\anaconda3\\lib\\site-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from h5py) (1.19.2)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\alex\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (0.11.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (50.3.1.post20201107)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (1.19.2)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (0.35.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (3.3.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (1.26.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (3.14.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (0.4.2)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (1.35.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from tensorboard) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\alex\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "### BEWARE:Tensorflow is stochastic - this means the model will not be replicated exactly. \n",
    "### Use GA_Load_Model for reproduction\n",
    "\n",
    "!pip install mlxtend\n",
    "\n",
    "!pip install h5py pyyaml\n",
    "\n",
    "!pip install tensorboard\n",
    "\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tLftnb5sBe7B"
   },
   "outputs": [],
   "source": [
    "#Load packages\n",
    "\n",
    "%load_ext tensorboard\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iBsKz40OAGDU"
   },
   "outputs": [],
   "source": [
    "### Packages necessary for model construction \n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.callbacks\n",
    "import datetime \n",
    "import statistics\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrEcBaVWVVkb"
   },
   "outputs": [],
   "source": [
    "#Read the Data\n",
    "\n",
    "UN_Data = pd.read_csv('GA_Query_CleanLIWC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "executionInfo": {
     "elapsed": 4369,
     "status": "ok",
     "timestamp": 1611639237251,
     "user": {
      "displayName": "Kimo Gandall",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimtqABjWQhcZq3EN733En5BNQLUL5UuOeyZFu4=s64",
      "userId": "00887894863642395375"
     },
     "user_tz": 480
    },
    "id": "FNUqnWTFS4y2",
    "outputId": "cf54ea17-a224-4830-8f6b-554ee9bafaf0"
   },
   "outputs": [],
   "source": [
    "#Inspect and Clean the Data\n",
    "\n",
    "UN_Data.head(5)\n",
    "\n",
    "UN_Data.drop(['Unnamed: 0'], axis = 1, inplace= True)\n",
    "\n",
    "UN_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 4368,
     "status": "ok",
     "timestamp": 1611639237252,
     "user": {
      "displayName": "Kimo Gandall",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimtqABjWQhcZq3EN733En5BNQLUL5UuOeyZFu4=s64",
      "userId": "00887894863642395375"
     },
     "user_tz": 480
    },
    "id": "tkn1c4RqeEdO",
    "outputId": "d56ecbce-990a-427d-e279-772f8546aeac"
   },
   "outputs": [],
   "source": [
    "#Inspect the data by key descriptive statistics\n",
    "\n",
    "UN_Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "executionInfo": {
     "elapsed": 4367,
     "status": "ok",
     "timestamp": 1611639237253,
     "user": {
      "displayName": "Kimo Gandall",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimtqABjWQhcZq3EN733En5BNQLUL5UuOeyZFu4=s64",
      "userId": "00887894863642395375"
     },
     "user_tz": 480
    },
    "id": "1c56fLBjJKA3",
    "outputId": "8b5f5028-9f16-4543-a585-e014b90e8ef7"
   },
   "outputs": [],
   "source": [
    "#Group the data by our label (dependent variable) of policy passage\n",
    "\n",
    "UN_Data.groupby(['Policy Passed']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the data \n",
    "\n",
    "UN_Data1 = tf.keras.utils.normalize(UN_Data.drop(columns = ['Policy Passed']))\n",
    "\n",
    "UN_Data1[\"Policy Passed\"] = UN_Data['Policy Passed']\n",
    "\n",
    "UN_Data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6BF8hmXGEnF"
   },
   "outputs": [],
   "source": [
    "#Divide our variables between the independent variables (features) and dependent variables (policy passage)\n",
    "\n",
    "labels = UN_Data ['Policy Passed']\n",
    "features = UN_Data.drop(columns= ['Policy Passed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Null Values\n",
    "\n",
    "features = features.fillna(0)\n",
    "labels = labels.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4359,
     "status": "ok",
     "timestamp": 1611639237254,
     "user": {
      "displayName": "Kimo Gandall",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimtqABjWQhcZq3EN733En5BNQLUL5UuOeyZFu4=s64",
      "userId": "00887894863642395375"
     },
     "user_tz": 480
    },
    "id": "4FJRWpUNH8Dk",
    "outputId": "fe514d19-f576-4030-c91f-fc2b562d2213"
   },
   "outputs": [],
   "source": [
    "#Inspect shape of features\n",
    "\n",
    "features = pd.get_dummies(features)\n",
    "features.shape[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-oGgPi4CG0xx"
   },
   "outputs": [],
   "source": [
    "#Define type of feature and label values\n",
    "\n",
    "features = features.values.astype('float32')\n",
    "labels = labels.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOea_aP_HPSE"
   },
   "outputs": [],
   "source": [
    "#Data Sets for Training\n",
    "\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2)\n",
    "features_train, features_validation, labels_train, labels_validation = train_test_split(features_train, labels_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHSYOIsh5vq4"
   },
   "outputs": [],
   "source": [
    "#Define Precision, Recall, and F1 score metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def f1_metric(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall_keras = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall_keras\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision_keras = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4VQ_OqkCHkLM"
   },
   "outputs": [],
   "source": [
    "#Create your model\n",
    "\n",
    "model1 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model2 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model3 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model4 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model5 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "\n",
    "model6 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model7 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model8 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model9 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model10 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "\n",
    "model11 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model12 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model13 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model14 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model15 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "\n",
    "model16 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model17 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model18 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model19 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model20 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "\n",
    "model21 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model22 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model23 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model24 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model25 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "\n",
    "model26 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model27 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model28 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model29 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])\n",
    "model30 = tf.keras.Sequential([keras.layers.Dense(32, input_shape=(100,)),keras.layers.Dropout(.20),keras.layers.Dense(16, activation= 'relu'),keras.layers.Dropout(.10),keras.layers.Dense(2, activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "executionInfo": {
     "elapsed": 6114,
     "status": "ok",
     "timestamp": 1611639239019,
     "user": {
      "displayName": "Kimo Gandall",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimtqABjWQhcZq3EN733En5BNQLUL5UuOeyZFu4=s64",
      "userId": "00887894863642395375"
     },
     "user_tz": 480
    },
    "id": "7JTlq8aH8mzi",
    "outputId": "a7831e8c-a787-4b03-8006-c9aebd129183"
   },
   "outputs": [],
   "source": [
    "### Inspect form of model\n",
    "\n",
    "tf.keras.utils.plot_model(model1, to_file='model.png', show_shapes = True, show_dtype=True, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6114,
     "status": "ok",
     "timestamp": 1611639239020,
     "user": {
      "displayName": "Kimo Gandall",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimtqABjWQhcZq3EN733En5BNQLUL5UuOeyZFu4=s64",
      "userId": "00887894863642395375"
     },
     "user_tz": 480
    },
    "id": "52Vb8b-qSIQ4",
    "outputId": "dd0ce729-358b-43ac-8d65-6c1f00ba812a"
   },
   "outputs": [],
   "source": [
    "#Check Trainable Parameters\n",
    "# Note: All the models are similarly structured\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vyx2tehuTPfe"
   },
   "outputs": [],
   "source": [
    "#Set checkpoints, metrics, loss, and optimizer functions for the model\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model1.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model2.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model3.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model4.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model5.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "\n",
    "model6.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model7.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model8.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model9.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model10.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "\n",
    "model11.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model12.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model13.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model14.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model15.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "\n",
    "model16.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model17.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model18.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model19.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model20.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "\n",
    "model21.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model22.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model23.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model24.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model25.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "\n",
    "model26.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model27.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model28.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model29.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])\n",
    "model30.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc', precision, recall, f1_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 150145,
     "status": "error",
     "timestamp": 1611639383055,
     "user": {
      "displayName": "Kimo Gandall",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GimtqABjWQhcZq3EN733En5BNQLUL5UuOeyZFu4=s64",
      "userId": "00887894863642395375"
     },
     "user_tz": 480
    },
    "id": "RhwA7DthFS72",
    "outputId": "64a70fe2-c811-4102-e25e-f708c8ee64e8"
   },
   "outputs": [],
   "source": [
    "#Run the model\n",
    "\n",
    "print(\"Model 1 Fitting\")\n",
    "history1 = model1.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 2 Fitting\")\n",
    "history2 = model2.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 3 Fitting\")\n",
    "history3 = model3.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 4 Fitting\")\n",
    "history4 = model4.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 5 Fitting\")\n",
    "history5 = model5.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"Model 6 Fitting\")\n",
    "history6 = model6.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 7 Fitting\")\n",
    "history7 = model7.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 8 Fitting\")\n",
    "history8 = model8.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 9 Fitting\")\n",
    "history9 = model9.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 10 Fitting\")\n",
    "history10 = model10.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"Model 11 Fitting\")\n",
    "history11 = model11.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 12 Fitting\")\n",
    "history12 = model12.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 13 Fitting\")\n",
    "history13 = model13.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 14 Fitting\")\n",
    "history14 = model14.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 15 Fitting\")\n",
    "history15 = model15.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"Model 16 Fitting\")\n",
    "history16 = model16.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 17 Fitting\")\n",
    "history17 = model17.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 18 Fitting\")\n",
    "history18 = model18.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 19 Fitting\")\n",
    "history19 = model19.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 20 Fitting\")\n",
    "history20 = model20.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"Model 21 Fitting\")\n",
    "history21 = model21.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 22 Fitting\")\n",
    "history22 = model22.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 23 Fitting\")\n",
    "history23 = model23.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 24 Fitting\")\n",
    "history24 = model24.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 25 Fitting\")\n",
    "history25 = model25.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "\n",
    "print(\"Model 26 Fitting\")\n",
    "history26 = model26.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 27 Fitting\")\n",
    "history27 = model27.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 28 Fitting\")\n",
    "history28 = model28.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 29 Fitting\")\n",
    "history29 = model29.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])\n",
    "print(\"Model 30 Fitting\")\n",
    "history30 = model30.fit(features_train, labels_train, epochs=30, validation_data=(features_validation, labels_validation), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfHp9ww0FWvB"
   },
   "outputs": [],
   "source": [
    "#Run model predictions\n",
    "\n",
    "# Model 1 \n",
    "prediction_features_1 = model1.predict(features_test)\n",
    "performance1 = model1.evaluate(features_test, labels_test)\n",
    "print(performance1)\n",
    "# Model 2 \n",
    "prediction_features_2 = model2.predict(features_test)\n",
    "performance2 = model2.evaluate(features_test, labels_test)\n",
    "print(performance1)\n",
    "# Model 3 \n",
    "prediction_features_3 = model3.predict(features_test)\n",
    "performance3 = model3.evaluate(features_test, labels_test)\n",
    "print(performance1)\n",
    "# Model 4 \n",
    "prediction_features_4 = model4.predict(features_test)\n",
    "performance4 = model4.evaluate(features_test, labels_test)\n",
    "print(performance4)\n",
    "# Model 5 \n",
    "prediction_features_5 = model5.predict(features_test)\n",
    "performance5 = model5.evaluate(features_test, labels_test)\n",
    "print(performance5)\n",
    "\n",
    "# Model 6 \n",
    "prediction_features_6 = model6.predict(features_test)\n",
    "performance6 = model6.evaluate(features_test, labels_test)\n",
    "print(performance6)\n",
    "# Model 7\n",
    "prediction_features_7 = model7.predict(features_test)\n",
    "performance7 = model7.evaluate(features_test, labels_test)\n",
    "print(performance7)\n",
    "# Model 8 \n",
    "prediction_features_8 = model8.predict(features_test)\n",
    "performance8 = model8.evaluate(features_test, labels_test)\n",
    "print(performance8)\n",
    "# Model 9\n",
    "prediction_features_9 = model9.predict(features_test)\n",
    "performance9 = model9.evaluate(features_test, labels_test)\n",
    "print(performance9)\n",
    "# Model 10\n",
    "prediction_features_10 = model10.predict(features_test)\n",
    "performance10 = model10.evaluate(features_test, labels_test)\n",
    "print(performance10)\n",
    "\n",
    "# Model 11 \n",
    "prediction_features_11 = model11.predict(features_test)\n",
    "performance11 = model11.evaluate(features_test, labels_test)\n",
    "print(performance11)\n",
    "# Model 12 \n",
    "prediction_features_12 = model12.predict(features_test)\n",
    "performance12 = model12.evaluate(features_test, labels_test)\n",
    "print(performance12)\n",
    "# Model 13 \n",
    "prediction_features_13 = model13.predict(features_test)\n",
    "performance13 = model13.evaluate(features_test, labels_test)\n",
    "print(performance13)\n",
    "# Model 14 \n",
    "prediction_features_14 = model14.predict(features_test)\n",
    "performance14 = model14.evaluate(features_test, labels_test)\n",
    "print(performance14)\n",
    "# Model 15 \n",
    "prediction_features_15 = model15.predict(features_test)\n",
    "performance15 = model15.evaluate(features_test, labels_test)\n",
    "print(performance15)\n",
    "\n",
    "# Model 16\n",
    "prediction_features_16 = model16.predict(features_test)\n",
    "performance16 = model16.evaluate(features_test, labels_test)\n",
    "print(performance16)\n",
    "# Model 17\n",
    "prediction_features_17 = model17.predict(features_test)\n",
    "performance17 = model17.evaluate(features_test, labels_test)\n",
    "print(performance17)\n",
    "# Model 18 \n",
    "prediction_features_18 = model18.predict(features_test)\n",
    "performance18 = model18.evaluate(features_test, labels_test)\n",
    "print(performance18)\n",
    "# Model 19\n",
    "prediction_features_19 = model19.predict(features_test)\n",
    "performance19 = model19.evaluate(features_test, labels_test)\n",
    "print(performance19)\n",
    "# Model 20 \n",
    "prediction_features_20 = model20.predict(features_test)\n",
    "performance20 = model20.evaluate(features_test, labels_test)\n",
    "print(performance20)\n",
    "\n",
    "# Model 21\n",
    "prediction_features_21 = model21.predict(features_test)\n",
    "performance21 = model21.evaluate(features_test, labels_test)\n",
    "print(performance21)\n",
    "# Model 22\n",
    "prediction_features_22 = model22.predict(features_test)\n",
    "performance22 = model22.evaluate(features_test, labels_test)\n",
    "print(performance22)\n",
    "# Model 23\n",
    "prediction_features_23 = model23.predict(features_test)\n",
    "performance23 = model23.evaluate(features_test, labels_test)\n",
    "print(performance23)\n",
    "# Model 24 \n",
    "prediction_features_24 = model24.predict(features_test)\n",
    "performance24 = model24.evaluate(features_test, labels_test)\n",
    "print(performance24)\n",
    "# Model 25\n",
    "prediction_features_25 = model25.predict(features_test)\n",
    "performance25 = model25.evaluate(features_test, labels_test)\n",
    "print(performance25)\n",
    "\n",
    "# Model 26 \n",
    "prediction_features_26 = model26.predict(features_test)\n",
    "performance26 = model26.evaluate(features_test, labels_test)\n",
    "print(performance26)\n",
    "# Model 27 \n",
    "prediction_features_27 = model27.predict(features_test)\n",
    "performance27 = model27.evaluate(features_test, labels_test)\n",
    "print(performance27)\n",
    "# Model 28 \n",
    "prediction_features_28 = model28.predict(features_test)\n",
    "performance28 = model28.evaluate(features_test, labels_test)\n",
    "print(performance28)\n",
    "# Model 29\n",
    "prediction_features_29 = model29.predict(features_test)\n",
    "performance29 = model29.evaluate(features_test, labels_test)\n",
    "print(performance29)\n",
    "# Model 30 \n",
    "prediction_features_30 = model30.predict(features_test)\n",
    "performance30 = model30.evaluate(features_test, labels_test)\n",
    "print(performance30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-kn2xq4Ts7s-"
   },
   "outputs": [],
   "source": [
    "# Averages\n",
    "\n",
    "# Loss\n",
    "loss_avg = (performance1[0] + performance2[0] + performance3[0] + performance4[0] + performance5[0] + performance6[0] + performance7[0] + performance8[0] + performance9[0] + performance10[0]\n",
    "            + performance11[0] + performance12[0] + performance13[0] + performance14[0] + performance15[0] + performance16[0] + performance17[0] + performance18[0] + performance19[0] + performance20[0]\n",
    "            + performance21[0] + performance22[0] + performance23[0] + performance24[0] + performance25[0] + performance26[0] + performance27[0] + performance28[0] + performance29[0] + performance30[0])/30\n",
    "print(\"Loss Average: \", loss_avg)\n",
    "\n",
    "# Accuracy\n",
    "acc_avg =(performance1[1] + performance2[1] + performance3[1] + performance4[1] + performance5[1] + performance6[1] + performance7[1] + performance8[1] + performance9[1] + performance10[1]\n",
    "            + performance11[1] + performance12[1] + performance13[1] + performance14[1] + performance15[1] + performance16[1] + performance17[1] + performance18[1] + performance19[1] + performance20[1]\n",
    "            + performance21[1] + performance22[1] + performance23[1] + performance24[1] + performance25[1] + performance26[1] + performance27[1] + performance28[1] + performance29[1] + performance30[1])/30\n",
    "print(\"Accuraccy Average: \", acc_avg)\n",
    "\n",
    "# Precision\n",
    "precision_avg = (performance1[2] + performance2[2] + performance3[2] + performance4[2] + performance5[2] + performance6[2] + performance7[2] + performance8[2] + performance9[2] + performance10[2]\n",
    "            + performance11[2] + performance12[2] + performance13[2] + performance14[2] + performance15[2] + performance16[2] + performance17[2] + performance18[2] + performance19[2] + performance20[2]\n",
    "            + performance21[2] + performance22[2] + performance23[2] + performance24[2] + performance25[2] + performance26[2] + performance27[2] + performance28[2] + performance29[2] + performance30[2])/30\n",
    "print(\"Precision Average: \", precision_avg)\n",
    "\n",
    "# Recall\n",
    "recall_avg = (performance1[3] + performance2[3] + performance3[3] + performance4[3] + performance5[3] + performance6[3] + performance7[3] + performance8[3] + performance9[3] + performance10[3]\n",
    "            + performance11[3] + performance12[3] + performance13[3] + performance14[3] + performance15[3] + performance16[3] + performance17[3] + performance18[3] + performance19[3] + performance20[3]\n",
    "            + performance21[3] + performance22[3] + performance23[3] + performance24[3] + performance25[3] + performance26[3] + performance27[3] + performance28[3] + performance29[3] + performance30[3])/30\n",
    "print(\"Recall Average: \", recall_avg)\n",
    "\n",
    "# f1_metric\n",
    "f1_avg = (performance1[4] + performance2[4] + performance3[4] + performance4[4] + performance5[4] + performance6[4] + performance7[4] + performance8[4] + performance9[4] + performance10[4]\n",
    "            + performance11[4] + performance12[4] + performance13[4] + performance14[4] + performance15[4] + performance16[4] + performance17[4] + performance18[4] + performance19[4] + performance20[4]\n",
    "            + performance21[4] + performance22[4] + performance23[4] + performance24[4] + performance25[4] + performance26[4] + performance27[4] + performance28[4] + performance29[4] + performance30[4])/30\n",
    "print(\"F1 Average: \", f1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XuwAUg5_KOz4"
   },
   "outputs": [],
   "source": [
    "#Take the standard deviation of the model samples\n",
    "\n",
    "#Loss SE\n",
    "Loss_SE = statistics.stdev([performance1[0], performance2[0], performance3[0], performance4[0], performance5[0],\n",
    "                  performance6[0], performance7[0], performance8[0], performance9[0], performance10[0],\n",
    "                  performance11[0], performance12[0], performance13[0], performance14[0], performance15[0],\n",
    "                  performance16[0], performance17[0], performance18[0], performance19[0], performance20[0], \n",
    "                  performance21[0], performance22[0], performance23[0], performance24[0], performance25[0],\n",
    "                  performance26[0], performance27[0], performance28[0], performance29[0], performance30[0]])\n",
    "print(\"Loss SE:\", Loss_SE)\n",
    "\n",
    "#Accuracy SE\n",
    "Acc_SE = statistics.stdev([performance1[1], performance2[1], performance3[1], performance4[1], performance5[1],\n",
    "                  performance6[1], performance7[1], performance8[1], performance9[1], performance10[1],\n",
    "                  performance11[1], performance12[1], performance13[1], performance14[1], performance15[1],\n",
    "                  performance16[1], performance17[1], performance18[1], performance19[1], performance20[1], \n",
    "                  performance21[1], performance22[1], performance23[1], performance24[1], performance25[1],\n",
    "                  performance26[1], performance27[1], performance28[1], performance29[1], performance30[1]])\n",
    "print(\"Accuraccy SE: \", Acc_SE)\n",
    "\n",
    "#Precision SE\n",
    "precision_SE = statistics.stdev([performance1[2], performance2[2], performance3[2], performance4[2], performance5[2],\n",
    "                  performance6[2], performance7[2], performance8[2], performance9[2], performance10[2],\n",
    "                  performance11[2], performance12[2], performance13[2], performance14[2], performance15[2],\n",
    "                  performance16[2], performance17[2], performance18[2], performance19[2], performance20[2], \n",
    "                  performance21[2], performance22[2], performance23[2], performance24[2], performance25[2],\n",
    "                  performance26[2], performance27[2], performance28[2], performance29[2], performance30[2]])\n",
    "print(\"Precision SE: \", precision_SE)\n",
    "\n",
    "#Recall \n",
    "Recall_SE = statistics.stdev([performance1[3], performance2[3], performance3[3], performance4[3], performance5[3],\n",
    "                  performance6[3], performance7[3], performance8[3], performance9[3], performance10[3],\n",
    "                  performance11[3], performance12[3], performance13[3], performance14[3], performance15[3],\n",
    "                  performance16[3], performance17[3], performance18[3], performance19[3], performance20[3], \n",
    "                  performance21[3], performance22[3], performance23[3], performance24[3], performance25[3],\n",
    "                  performance26[3], performance27[3], performance28[3], performance29[3], performance30[3]])\n",
    "print(\"Recall SE: \", Recall_SE)\n",
    "\n",
    "#F1 Score\n",
    "F1_Score_SE = statistics.stdev([performance1[4], performance2[4], performance3[4], performance4[4], performance5[4],\n",
    "                  performance6[4], performance7[4], performance8[4], performance9[4], performance10[4],\n",
    "                  performance11[4], performance12[4], performance13[4], performance14[4], performance15[4],\n",
    "                  performance16[4], performance17[4], performance18[4], performance19[4], performance20[4], \n",
    "                  performance21[4], performance22[4], performance23[4], performance24[4], performance25[4],\n",
    "                  performance26[4], performance27[4], performance28[4], performance29[4], performance30[4]])\n",
    "print(\"F1_Score_SE: \", F1_Score_SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMpLKJ4OKt-X"
   },
   "outputs": [],
   "source": [
    "#Tensorflow Graphics\n",
    "\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GA_ParliHeg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
